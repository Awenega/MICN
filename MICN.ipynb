{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MICN: Multi-Scale Local and Global Context Modeling for Long-Term Series Forecasting**\n",
        "\n",
        "Re-implementation of the [original paper](https://openreview.net/pdf?id=zt53IDUR1U)\n",
        "\n",
        "Students:\n",
        "\n",
        "- *Francesco Sudoso 1808353*\n",
        "- *Francesco Sasanelli 2014433*\n"
      ],
      "metadata": {
        "id": "Ih1g-TdiPplF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Description of the Paper**\n",
        "In this project we reimplemented the original paper MICN: Multi-Scale Local and Global Context Modeling for Long-Term Series Forecasting.\n",
        "\n",
        "The main goal of the authors is to address the challenges posed by Transformer-based methods in long-term series forecasting, particularly their high complexity in computing global correlations (caused by the attention mechanism) and the lack of targeted local feature modeling.\n",
        "\n",
        "For this reason, they propose a new method called Multi-Scale Isometric Convolution Network (**MICN**) that combines local feature extraction with global correlation modeling, achieving greater accuracy and efficiency than existing methods. The approach is based on *convolutional operations*, demonstrating the advantages of this method over using *Transformers*.\n",
        "\n",
        "The most important results of this implementation are the following:\n",
        "- In order to achieve linear computational complexity, they have developed a convolution-based structure to replace the self-attention mechanism.\n",
        "- Develop a local-global architecture for extraction and aggregation of informations and patterns, enabling effective long-term dependency modeling and outperforming self-attention mechanisms."
      ],
      "metadata": {
        "id": "RAvDsQzMFv09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Main aspects of MICN**\n",
        "We will see that MICN uses multiple branches, each obtained by different convolution kernels, to capture various potential patterns within the time series. Each branch extracts local features using a downsampling convolution, focusing on capturing short-term changes in the data. On top of the local feature extraction, MICN uses isometric convolution to model global correlations. After extracting local features and modeling global correlations, the information from various branches is merged.\n",
        "The superiority of their local-global module is shown by comparing previous models like Autoformer, which uses auto-correlation."
      ],
      "metadata": {
        "id": "V8RMxEW3F3BW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Pytorch Code**\n",
        "\n",
        "First of all, we import the dependencies that will be used to execute the code:"
      ],
      "metadata": {
        "id": "8YQ1erHeF6nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "_rb6HfQfpQi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Dataset and Dataloader implementation\n",
        "Regarding the dataset, the dataloader and the related split between train, validation and test set, we followed what the author said:\n",
        "\n",
        "> We follow standard protocol (Zhou et al., 2021) and split all datasets into training, validation and test set in chronological order by the ratio of 6:2:2 for the ETT dataset and 7:1:2 for the other datasets.\n",
        "\n",
        "The protocol referred by the author is the one defined by the [Informer](https://arxiv.org/abs/2012.07436) paper (model that will be used as a comparison).\n",
        "\n",
        "Our initial idea was to split any dataset into 80/10/10.\n",
        "But realizing that there is a precise protocol for managing these specific datasets, we chose to follow their approach. Therefore, the approach used by Informer (and by all the models used in performance comparison) consists in splitting the \"ETTm2\" dataset based on the quarters of an hour present in a month (given that the measurements of electricity consumption of the dataset are taken every quarter of an hour). In particular, the train set contains 12 months of measurements, and the validation and test sets 4 and 4 respectively.\n",
        "All other datasets will follow the 70/10/20 rule."
      ],
      "metadata": {
        "id": "3iAV7J6vzkZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, seq_len, pred_len, type, freq, device):\n",
        "        self.type = type\n",
        "        self.device = device\n",
        "        self.seq_len, self.pred_len = seq_len, pred_len\n",
        "\n",
        "        df = pd.read_csv(path)\n",
        "        self.feature_dim = len(df.columns)-1\n",
        "\n",
        "        if path == 'ETTm2.csv':\n",
        "            QUARTER_HOURS_IN_ONE_MONTH = 30 * 24 * 4\n",
        "            if type == 'train': #12 months\n",
        "                start_row, end_row = 0, 12 * QUARTER_HOURS_IN_ONE_MONTH\n",
        "            elif type == 'val': #4 months\n",
        "                start_row, end_row = 12 * QUARTER_HOURS_IN_ONE_MONTH - self.seq_len, 16 * QUARTER_HOURS_IN_ONE_MONTH\n",
        "            elif type == 'test': #4 months\n",
        "                start_row, end_row = 16 * QUARTER_HOURS_IN_ONE_MONTH - self.seq_len, 20 * QUARTER_HOURS_IN_ONE_MONTH\n",
        "        else:\n",
        "            rows = len(df)\n",
        "            if type == 'train':\n",
        "                start_row, end_row = 0, int(rows * 0.7)\n",
        "            elif type == 'val':\n",
        "                start_row, end_row = int(rows * 0.7) - self.seq_len, int(rows * 0.8)\n",
        "            elif type == 'test':\n",
        "                start_row, end_row = int(rows * 0.8) - self.seq_len, rows\n",
        "\n",
        "        #Feature Scaling\n",
        "        scaler = StandardScaler()\n",
        "        all_features = df[df.columns[1:]]\n",
        "        train_features = all_features[0:12*QUARTER_HOURS_IN_ONE_MONTH] if path == 'ETTm2.csv' else all_features[0:int(len(df)*0.7)]\n",
        "        scaler.fit(train_features.values)\n",
        "        data = scaler.transform(all_features.values)\n",
        "\n",
        "        self.time_features = self.get_time_features(df.iloc[start_row:end_row, 0], freq)\n",
        "        self.data_x = data[start_row:end_row]\n",
        "        self.data_y = data[start_row:end_row]\n",
        "\n",
        "    def __len__(self):\n",
        "        #Denotes the total number of samples\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #Generates one sample of data\n",
        "        seq_x = torch.from_numpy(self.data_x[index : (index+self.seq_len)]).float().to(self.device)\n",
        "        seq_y = torch.from_numpy(self.data_y[index : (index+self.seq_len+self.pred_len)]).float()\n",
        "        time_x = torch.from_numpy(self.time_features[index : (index+self.seq_len)]).float().to(self.device)\n",
        "        time_y = torch.from_numpy(self.time_features[index : (index+self.seq_len+self.pred_len)]).float().to(self.device)\n",
        "        return seq_x, seq_y, time_x, time_y\n",
        "\n",
        "    def get_time_features(self, dates, freq):\n",
        "        #Convert a timestamp to vector feature\n",
        "        features = pd.DataFrame({'date': pd.to_datetime(dates)})\n",
        "        features['month'] = features['date'].dt.month\n",
        "        features['day'] = features['date'].dt.day\n",
        "        features['weekday'] = features['date'].dt.weekday\n",
        "        features['hour'] = features['date'].dt.hour\n",
        "        features['minute'] = features['date'].dt.minute // 15\n",
        "\n",
        "        freq_map = {\n",
        "            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n",
        "            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n",
        "            't':['month','day','weekday','hour','minute'],\n",
        "        }\n",
        "\n",
        "        return features[freq_map[freq]].values\n",
        "\n",
        "    def get_Dataloader(self):\n",
        "        if self.type == 'test':\n",
        "            loader = DataLoader(self, batch_size=32, shuffle=False, drop_last=True)\n",
        "        else: #train or val\n",
        "            loader = DataLoader(self, batch_size=32, shuffle=True, drop_last=True)\n",
        "        return loader"
      ],
      "metadata": {
        "id": "vdohO4LJ4QuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2 MICN Framework and Architecture**\n",
        "\n",
        "The overall structure of MICN is shown in the figure below.\n",
        "![Logo](https://github.com/Awenega/MICN/blob/main/images/MICN.png?raw=true)\n",
        "As we can see, it is composed by four blocks:\n",
        "- The **Multi-scale Hybrid Decomposition Block**, which is used to decompose the input series.\n",
        "- The **Embedding Block** to add positional information but also to map time-related features to a higher dimension\n",
        "- The **MIC Block** to predict seasonal information.\n",
        "- The **Regression Block** to predict trend-cyclical information.\n",
        "\n",
        "Since a time series can be seen as the sum of its trend and seasonality (and noise), the outputs of the MIC block and the Regression block are summed.\n",
        "\n",
        "![Time series decomp](https://github.com/Awenega/MICN/blob/main/images/decomp.PNG?raw=true)"
      ],
      "metadata": {
        "id": "jO4jdZemrT1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.1 MICN code**\n",
        "<a class=\"anchor\" name=\"3.2.1\"></a>\n",
        "To explain how we implemented the model, we will use a Bottom-Up approach: we will start with the code of each block previously listed, and then we go up to the model itself. Accordingly, we will provide the explanation of the following blocks in order:\n",
        "1. MHD Block\n",
        "2. Regression Block\n",
        "3. Embedding Block\n",
        "4. MIC Block (which is divided into Local and Global Blocks)\n",
        "5. MICN model\n",
        "\n",
        "In the next section we start the explaination from the MHD Block."
      ],
      "metadata": {
        "id": "mNROGvkqFoaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.2 Multi-Scale Hybrid Decomposition Block**\n",
        "One of the main methods of decomposing time series into their respective trends and seasonality is to use the moving average. In fact, this approach was also used to implement [Autoformer](https://arxiv.org/abs/2106.13008) and [FEDformer](https://arxiv.org/abs/2201.12740), which are models for predicting long-term series, which will be used as a comparison of the results that MICN will obtain.\n",
        "\n",
        "This method consists of using Avgpool layer with fixed kernels. But the authors propose to use several different kernels for the AvgPool operation. This approach allows for the separation of various patterns in the trend-cyclical and seasonal parts of the series, that, at the end, are integrated through a mean operation.\n",
        "\n",
        "The class *moving_avg* is taken from the [Autoformer](https://github.com/thuml/Autoformer/blob/main/layers/Autoformer_EncDec.py) implementation and we have done some modifications to make the code more readable and interpretable.\n",
        "\n",
        "Instead, the class *Series_Decomposer* is built on top of the previous class. Specifically, depending on the case in which we need to decompose the series (whether with multiple kernels or whether with a single one), the class will consist of an array of avgpools, each with a different kernel. The purpose is to extract different patterns and eventually average them out.\n",
        "\n",
        "This block produces two outputs: the first, which is the extracted seasonality, will serve as input to the next block we will discuss, which is the embedding. While the second, the extracted trend, will be used in the forward pass of the MICN model to apply regression or mean to make a prediction about the final trend.\n",
        "\n",
        "In the next section, we will explain the Embedding block."
      ],
      "metadata": {
        "id": "rJpkRs_sAePi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class moving_avg(nn.Module):\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.pad_size = (kernel_size - 1) // 2\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front_padding = x[:, 0:1, :].repeat(1, self.pad_size, 1)\n",
        "        end_padding = x[:, -1:, :].repeat(1, self.pad_size, 1)\n",
        "        x_padded = torch.cat([front_padding, x, end_padding], dim=1)\n",
        "        x_smoothed = self.avg(x_padded.permute(0, 2, 1))\n",
        "        x_smoothed = x_smoothed.permute(0, 2, 1)\n",
        "        return x_smoothed\n",
        "\n",
        "class Series_Decomposer(nn.Module):\n",
        "    def __init__(self, kernel_size, multi=False):\n",
        "        super(Series_Decomposer, self).__init__()\n",
        "        self.multi = multi\n",
        "        self.moving_avg_layers = nn.ModuleList([moving_avg(kernel, stride=1) for kernel in kernel_size]) if multi else moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def compute_moving_avgs(self, x):\n",
        "        moving_means = []\n",
        "        seasonals = []\n",
        "        if self.multi:\n",
        "            for layer in self.moving_avg_layers:\n",
        "                moving_avg = layer(x)\n",
        "                seasonal = x - moving_avg\n",
        "                moving_means.append(moving_avg)\n",
        "                seasonals.append(seasonal)\n",
        "        else:\n",
        "            moving_avg = self.moving_avg_layers(x)\n",
        "            seasonal = x - moving_avg\n",
        "            moving_means.append(moving_avg)\n",
        "            seasonals.append(seasonal)\n",
        "\n",
        "        return seasonals, moving_means\n",
        "\n",
        "    def forward(self, x):\n",
        "        seasonals, moving_means = self.compute_moving_avgs(x)\n",
        "        seasonal = sum(seasonals) / len(seasonals)\n",
        "        moving_mean = sum(moving_means) / len(moving_means)\n",
        "\n",
        "        return seasonal, moving_mean"
      ],
      "metadata": {
        "id": "RYFSzE3f3pLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.3 Embedding Block**\n",
        "\n",
        "The Embedding Block is described in the Figure below.\n",
        "\n",
        "![Embedding Block](https://github.com/Awenega/MICN/blob/main/images/Embedding.png?raw=true)\n",
        "\n",
        "As we can see:\n",
        "- $X_s$ is the output of the MHD block, so it is the seasonal decomposed part of the time series.\n",
        "- $X_{zero}$ is a tensor of all zeros.\n",
        "- $VE$, $PE$ and $TFE$ are respectively the Value Embedding, Positional Encoding and Time Feature Encoding.\n",
        "\n",
        "$X_s$ is concatenated to $X_{zero}$ and then passed as input to *ValueEmbedding*. At the end, the output of *ValueEmbedding* is summed to the output of the *PositionalEncoding* and to the output of the *TimeFeatureEncoding*.\n",
        "\n",
        "So, the first step is to concatenate $X_s$ and $X_{zero}$. We have done this step in the forward pass of the Embedding block. We report the code(not executable) that will be placed in the section of the MICN\n",
        "\n",
        "```python\n",
        "# embedding\n",
        "zeros = torch.zeros([seq_x.shape[0], self.pred_len, seq_x.shape[2]], device=seq_x.device)\n",
        "seasonal = seasonal[:, -self.seq_len:, :]\n",
        "seasonal_padded_zeros = torch.cat([seasonal, zeros], dim=1)\n",
        "```\n",
        "Then, the next step is to proceed with the embedding itself. But, since the authors said:\n",
        "\n",
        "> We follow the setting of FEDformer and adopt three parts to embed the input.<br>\n",
        "The process is: $X_{emb}^s$ = sum(TFE + PE + VE(Concat($X_s$,$X_{zero}$)))\n",
        "\n",
        "We decided to look at [FEDformer implementation](https://github.com/MAZiqing/FEDformer/blob/master/layers/Embed.py) and study their approach. But, looking deeper, we noticed that most models that predict long-term series use the same embedding technique. Consequently, it seemed the obvious choice for us to take this library as well and use it with our model. Of course, we modified some parts of the code to fit our model, but the basic operations are the same.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HtG5YAl39JpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add positional information to the model\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        pe = torch.zeros(max_len, embedding_dim).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, embedding_dim, 2).float() * -(math.log(10000.0) / embedding_dim)).exp()\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "# Utilizes a 1D convolutional layer to generate token embeddings from input sequences.\n",
        "# Each token is represented by a dense vector of output_feature_dim dimensions.\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, input_feature_dim, output_feature_dim):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.tokenConv = nn.Conv1d(in_channels=input_feature_dim, out_channels=output_feature_dim,\n",
        "                                    kernel_size=3, padding=1, padding_mode='circular')\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n",
        "        return x\n",
        "\n",
        "# It maps time-related features to a higher-dimensional space\n",
        "class TimeFeatureEmbedding(nn.Module):\n",
        "    def __init__(self, output_dim, freq='t'):\n",
        "        super(TimeFeatureEmbedding, self).__init__()\n",
        "\n",
        "        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n",
        "        input_dim = freq_map[freq]\n",
        "        self.embed = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embed(x)"
      ],
      "metadata": {
        "id": "y1kpqwNrJYRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the final Embedding Block is composed by these three embedding, that in the forward pass, we sum them up:"
      ],
      "metadata": {
        "id": "VNkEb3HxZQth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding Block\n",
        "class DataEmbedding(nn.Module):\n",
        "    def __init__(self, input_feature_dim, embedding_dim, freq, dropout, seq_len, pred_len):\n",
        "        super(DataEmbedding, self).__init__()\n",
        "\n",
        "        self.seq_len, self.pred_len = seq_len, pred_len\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(input_feature_dim, embedding_dim)\n",
        "        self.position_embedding = PositionalEmbedding(embedding_dim=embedding_dim)\n",
        "        self.temporal_embedding = TimeFeatureEmbedding(output_dim=embedding_dim, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, seq_x, seasonal, time):\n",
        "\n",
        "        zeros = torch.zeros([seq_x.shape[0], self.pred_len, seq_x.shape[2]], device=seq_x.device)\n",
        "        seasonal = seasonal[:, -self.seq_len:, :]\n",
        "        seasonal_padded_zeros = torch.cat([seasonal, zeros], dim=1)\n",
        "\n",
        "        seasonal_embedding = self.value_embedding(seasonal_padded_zeros) + self.position_embedding(seasonal_padded_zeros) + self.temporal_embedding(time)\n",
        "        return self.dropout(seasonal_embedding)"
      ],
      "metadata": {
        "id": "ydKgF7Y0KCgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.4 MIC Block**\n",
        "<a class=\"anchor\" name=\"3.2.4\"></a>\n",
        "\n",
        "The MIC Block is described in the figure below.\n",
        "![MIC Block](https://github.com/Awenega/MICN/blob/main/images/MIC.png?raw=true)\n",
        "\n",
        "Here, we can see that the output of the Embedding Block is passed as input to the MIC block. It contains several branches, with different scale sizes used to model potentially different temporal patterns.\n",
        "\n",
        "Moreover, the MIC block itself can be seen as the composition of 3 smaller blocks:\n",
        "- The Local Block, that extracts the local features.\n",
        "- The Global Block, that is designed to model the global correlations of the output of\n",
        "the Local Block\n",
        "- The Merge Block, that takes all the patterns and merge them together with Conv2d layer.\n",
        "\n",
        "At the end, some other operations are performed to obtain the final result.\n",
        "\n",
        "We will describe the code in order of the previously listed blocks."
      ],
      "metadata": {
        "id": "pqaLzfQsK-re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **3.2.4.1 Local and Global Block**\n",
        "<a class=\"anchor\" name=\"3.2.4.1\"></a>\n",
        "\n",
        "From the figure below, we can see what layers the Local Block and the Global Block are composed of.\n",
        "\n",
        "![Local Global Block](https://github.com/Awenega/MICN/blob/main/images/LocalGlobal.png?raw=true)\n"
      ],
      "metadata": {
        "id": "mnK-MQz3Zzck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the Local Block. It is composed by many convolutional layers, one for each kernel we are using to decompose the series.\n",
        "\n",
        "> For Conv1d, we set stride = kernel = i, which serves as compression of local features.\n",
        "\n"
      ],
      "metadata": {
        "id": "RWCGmQ4lcLXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Local(nn.Module):\n",
        "    def __init__(self, input_feature_dim, conv_kern, dropout):\n",
        "        super(Local, self).__init__()\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(in_channels=input_feature_dim, out_channels=input_feature_dim,\n",
        "                                             kernel_size=i,padding=i//2,stride=i)\n",
        "                                  for i in conv_kern])\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, seasonal, i):\n",
        "        # Downsampling and then Tanh & Dropout\n",
        "        seasonal_reshaped = seasonal.permute(0, 2, 1)\n",
        "        return self.dropout(self.tanh(self.conv[i](seasonal_reshaped)))"
      ],
      "metadata": {
        "id": "J7ruqg2JcGYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, the output of this block is passed to the Global Block.<br>\n",
        "This block is the one of the most important block in the paper since introduce a new approach to model the global correlations. Indeed:\n",
        "\n",
        "> A commonly used method for modeling global correlations is the self-attention\n",
        "mechanism. But in this paper, we use a variant of casual convolution, isometric convolution, as an alternative.\n",
        "\n",
        "Before we can apply the isometric convolution, we should first:\n",
        "\n",
        "> pads the sequence of length S with placeholders zero of length $Sâˆ’1$\n",
        "\n",
        "Since, in the Local Block we have downsapled the input, after the isometric convolution we upsample the sequence with ConvTranspose1d layer, as mentioned in the paper.\n",
        "\n"
      ],
      "metadata": {
        "id": "obGy6bJbdQvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Global(nn.Module):\n",
        "    def __init__(self, input_feature_dim, iso_kern, conv_kern, dropout):\n",
        "        super(Global, self).__init__()\n",
        "\n",
        "        self.isometric_conv = nn.ModuleList([nn.Conv1d(in_channels=input_feature_dim, out_channels=input_feature_dim,\n",
        "                                                   kernel_size=i,padding=0,stride=1)\n",
        "                                        for i in iso_kern])\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.norm = torch.nn.LayerNorm(input_feature_dim)\n",
        "\n",
        "        self.upsample_conv = nn.ModuleList([nn.ConvTranspose1d(in_channels=input_feature_dim, out_channels=input_feature_dim,\n",
        "                                                            kernel_size=i,padding=0,stride=i)\n",
        "                                        for i in conv_kern])\n",
        "\n",
        "    def forward(self, seasonal, local_out, i):\n",
        "        # we first pad the sequence\n",
        "        zeros = torch.zeros((local_out.shape[0], local_out.shape[1], local_out.shape[2]-1), device=local_out.device)\n",
        "        local_out_padded = torch.cat((zeros, local_out), dim=-1)\n",
        "        # then we apply isometric convolution\n",
        "        ret = self.dropout(self.tanh(self.isometric_conv[i](local_out_padded)))\n",
        "\n",
        "        iso_conv_result = local_out + ret\n",
        "        iso_conv_result = self.norm(iso_conv_result.permute(0, 2, 1)).permute(0, 2, 1)\n",
        "\n",
        "        # upsampling convolution\n",
        "        upsample_conv = self.dropout(self.tanh(self.upsample_conv[i](iso_conv_result)))\n",
        "\n",
        "        # Minimal truncation (the impact on the overall information content should be relatively small)\n",
        "        # It is done for computing (seasonal + upsample_conv), since both must have same shape\n",
        "        upsample_conv = upsample_conv[:, :, :seasonal.shape[1]].permute(0, 2, 1)\n",
        "\n",
        "        return self.norm(seasonal + upsample_conv)"
      ],
      "metadata": {
        "id": "IJEMjGaNdRMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can put Local Block and Global Block together for composing the Local_Global module illustrated in the previous [figure](#3.2.4.1).\n",
        "\n",
        "The first operation is to decompose with different kernels the seasonal component in order to extract all possible informations. Each decomposition, follows the Local Block that will extract the local feature and the Global block to model the global correlation. At the end of the process, we will have all the patterns that should be merged in the upcoming operations.\n"
      ],
      "metadata": {
        "id": "cAxS7H5gcG2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Local_Global(nn.Module):\n",
        "    def __init__(self, input_feature_dim, decomp_kern, conv_kern, iso_kern, dropout):\n",
        "        super(Local_Global, self).__init__()\n",
        "\n",
        "        self.decomp = nn.ModuleList([Series_Decomposer(kernel, multi=False) for kernel in decomp_kern])\n",
        "        self.local_block = Local(input_feature_dim, conv_kern, dropout)\n",
        "        self.global_block = Global(input_feature_dim, iso_kern, conv_kern, dropout)\n",
        "\n",
        "    def forward(self, seasonal_embedded, conv_kern):\n",
        "        patterns = []\n",
        "        for i in range(len(conv_kern)):\n",
        "            seasonal, _ = self.decomp[i](seasonal_embedded)\n",
        "            local_out = self.local_block(seasonal, i)\n",
        "            global_out = self.global_block(seasonal, local_out, i)\n",
        "            patterns.append(global_out)\n",
        "        return patterns"
      ],
      "metadata": {
        "id": "C8vbDDdJbFip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we have finished to implement the core part of [MIC](#3.2.4). The only things that are missing are the merge operation, the FeedForward and few other small operations.\n",
        "\n",
        "We first show the code for the FeedForward. It is a very simple class that can be implemented in many ways, but we preferred to make it as small and simple as possible to avoid increasing too much the number of parameters and computational complexity that we will have to deal with later during training."
      ],
      "metadata": {
        "id": "VLiZOqpNbMr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout):\n",
        "        super(FeedForward, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, input_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, patterns_merged):\n",
        "        return self.net(patterns_merged)"
      ],
      "metadata": {
        "id": "XjbCXh02jcWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can build the main block of the model, which is the MIC Block. It follows exactly the formulas described in the paper:\n",
        "\n",
        " - $Y_{s,l}^{merge} = (Conv2d(Y_{s,l}^{global,i}) $ <br><br> Here, we are merging all the results obtained from the Local_Global Block.<br><br>\n",
        " - $ Y_{s,l} = Norm(Y_{s,l}^{merge} + FeedForward(Y_{s,l}^{merge})) $ <br><br>\n",
        " Here, we are passing all the patterns merged to the feedforward network and then normalizing the sum of the patterns merged itself and the output. <br><br>\n",
        " - $ Y_s = Truncate(Projection(Y_{s,N})) $ <br><br>\n",
        " Here, we compute the final output of the prediction of the seasonal component by the projection and truncate operation on the previous output. <br><br>\n",
        " $ Y_S $ represents the final prediction about the seasonal part.\n",
        "\n"
      ],
      "metadata": {
        "id": "F5vCEzEPkQsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MIC(nn.Module):\n",
        "    def __init__(self, input_feature_dim, output_feature_dim, decomp_kern, conv_kern, iso_kern, dropout):\n",
        "        super(MIC, self).__init__()\n",
        "        self.conv_kern = conv_kern\n",
        "\n",
        "        self.local_global = Local_Global(input_feature_dim, decomp_kern, conv_kern, iso_kern, dropout)\n",
        "        self.merge = torch.nn.Conv2d(in_channels=input_feature_dim, out_channels=input_feature_dim, kernel_size=(len(conv_kern), 1))\n",
        "\n",
        "        self.feedForward = FeedForward(input_feature_dim, input_feature_dim*4, dropout)\n",
        "\n",
        "        self.norm = torch.nn.LayerNorm(input_feature_dim)\n",
        "        self.projection = nn.Linear(input_feature_dim, output_feature_dim)\n",
        "\n",
        "    def forward(self, seasonal_embedded):\n",
        "        patterns = self.local_global(seasonal_embedded, self.conv_kern)\n",
        "        patterns_list = [pattern.unsqueeze(1) for pattern in patterns]\n",
        "        # Merge operation is done by Conv2d layer. We need to change the shape of the input tensor\n",
        "        patterns_tensor = torch.cat(patterns_list, dim=1).permute(0, 3, 1, 2).to('cuda:0')\n",
        "        patterns_merged = self.merge(patterns_tensor).squeeze(-2).permute(0,2,1)\n",
        "        # Merge operation finished, then we remove the dimension that we added before with the unsqueeze(1) and we permute the shape back to the original shape\n",
        "\n",
        "        ret = self.norm(patterns_merged + self.feedForward(patterns_merged))\n",
        "        ret = self.projection(ret)\n",
        "        return ret"
      ],
      "metadata": {
        "id": "JtcxKTqMkSP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.5 MICN model**\n",
        "\n",
        "Now, we can pass to the MICN model itself. As mentioned earlier, the model consists of 4 main blocks.\n",
        "\n",
        "The first block that is used and applied in the forward is the MHD block, which is used to decompose the series into trend and seasonality.\n",
        "\n",
        "After that, the model uses a method of our choice between regression and mean to make a prediction about trend-cyclical.\n",
        "\n",
        "Next, padding is applied to the previously extracted seasonality to be serially passed as input to the embedding block and MIC block.\n",
        "\n",
        "The output of the MIC block will contain the prediction of the seasonality while the output of the regression or mean block, will contain the prediction of the trend.\n",
        "These two outputs will be summed to provide the final prediction.\n"
      ],
      "metadata": {
        "id": "p_Of5dLKAza_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MICN(nn.Module):\n",
        "    def __init__(self, input_feature_dim, output_feature_dim, seq_len, pred_len, embedding_dim, dropout, freq, mode,\n",
        "                decomp_kern, conv_kern, iso_kern):\n",
        "        super(MICN, self).__init__()\n",
        "\n",
        "        self.seq_len, self.pred_len, self.mode = seq_len, pred_len, mode\n",
        "\n",
        "        #MHD Block\n",
        "        self.decomp = Series_Decomposer(decomp_kern, multi=True)\n",
        "        #Embedding Block\n",
        "        self.embedding = DataEmbedding(input_feature_dim=input_feature_dim, embedding_dim=embedding_dim, freq=freq, dropout=dropout, seq_len = seq_len, pred_len = pred_len)\n",
        "        #MIC Block\n",
        "        self.mic = MIC(input_feature_dim=embedding_dim, output_feature_dim=output_feature_dim, decomp_kern=decomp_kern, conv_kern=conv_kern, iso_kern=iso_kern, dropout=dropout)\n",
        "        #Regression Block\n",
        "        self.regression = nn.Linear(seq_len, pred_len)\n",
        "\n",
        "    def forward(self, seq_x, time_y):\n",
        "\n",
        "        #series decomposition\n",
        "        seasonal, trend = self.decomp(seq_x)\n",
        "\n",
        "        #trend prediction\n",
        "        if self.mode == 'regression':\n",
        "            trend_pred = self.regression(trend.permute(0,2,1)).permute(0, 2, 1)\n",
        "        elif self.mode == 'mean':\n",
        "            mean = torch.mean(seq_x, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
        "            trend_pred = torch.cat([trend[:, -self.seq_len:, :], mean], dim=1)\n",
        "\n",
        "        #seasonal embedding\n",
        "        seasonal_embed = self.embedding(seq_x, seasonal, time_y)\n",
        "        #seasonal prediction\n",
        "        seasonal_pred = self.mic(seasonal_embed)\n",
        "        #timeseries prediction\n",
        "        time_series_pred = seasonal_pred[:, -self.pred_len:, :] + trend_pred[:, -self.pred_len:, :]\n",
        "\n",
        "        return time_series_pred"
      ],
      "metadata": {
        "id": "NhLeJJHYAdYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 **Training code**"
      ],
      "metadata": {
        "id": "oQAcbjmq6Eid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the implementation details of the paper it is mentioned that:\n",
        "> The training process is early stopped after three epochs if there is no loss degradation on the valid set.\n",
        "\n",
        "For this reason, we implemented a class to handle the early stopping.\n",
        "We took an already implemented and predefined [class](https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        ") and adapted it to our case."
      ],
      "metadata": {
        "id": "G7m2k2Nkxt_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, logger=None):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, path):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "yqMYA-S7zKpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we set some hyperparameters and some variable that we will use for the train. In this case, is possible to change the variable 'mode'.<br>\n",
        "After, is possible to choose the dataset that we want to have as input by changing the 'filename_dataset' variable.<br> The variables 'freq', 'seq_len', 'pred_len' and the kernels will depend on the dataset choosen: <br>\n",
        "- Regarding the 'freq', it is the sampling time for each dataset. For example, the dataset \"ETTm2\" contains electric consumption measurements taken every 15 minutes from July 2016 to July 2018. The table below define all the info about this sampling. The variable will be used for the vector decomposition of the date of the measurement (during the embedding).\n",
        "- For the prediction lenght, we can choose between 24,36 and 48 for national_illness dataset. For the other datasers, we can choose between 96, 192 and 336.\n",
        "- Regarding the kernels, we have set the kernals that the authors have used for their tests.\n",
        "\n",
        "Also, we create the dataloaders from the dataset."
      ],
      "metadata": {
        "id": "FATUTGJo5tfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/Awenega/MICN/blob/main/images/datasets.png?raw=true)"
      ],
      "metadata": {
        "id": "BH7mbFnHtGHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup of hyper-parameters\n",
        "mode = 'regression' # 'regression' or 'mean'\n",
        "embedding_dim = 512\n",
        "dropout = 0.05\n",
        "lr = 0.001\n",
        "gamma = 0.5\n",
        "patience = 3\n",
        "epochs = 20\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "os.makedirs('./checkpoints/') if not os.path.exists('./checkpoints/') else None\n",
        "\n",
        "#Setup of dataset filename and its respective frequency of data sampling\n",
        "filename_dataset = 'electricity.csv'\n",
        "if filename_dataset == 'ETTm2.csv' or filename_dataset == 'weather.csv':\n",
        "    freq = 't'\n",
        "elif filename_dataset == 'traffic.csv' or filename_dataset == 'electricity.csv':\n",
        "    freq = 'h'\n",
        "else:\n",
        "    freq = 'd'\n",
        "\n",
        "#Setup of seq_len and kernels depending on the dataset\n",
        "if filename_dataset != 'national_illness.csv':\n",
        "    seq_len = 96\n",
        "    pred_len = 96 # 96 or 192 or 336\n",
        "    conv_kern, decomp_kern = [12, 16], [13, 17]\n",
        "else:\n",
        "    seq_len = 36\n",
        "    pred_len = 24 # 24 or 36 or 48\n",
        "    conv_kern, decomp_kern = [12, 16], [13, 17]\n",
        "iso_kern = [(seq_len + pred_len + kern) // kern for kern in conv_kern]\n",
        "\n",
        "#Setup of the dataloaders\n",
        "train_data, val_data, test_data = [Dataset(f'{filename_dataset}', seq_len, pred_len, type, freq, device) for type in ['train', 'val', 'test']]\n",
        "train_loader, val_loader, test_loader = [dataset.get_Dataloader() for dataset in [train_data, val_data, test_data]]\n",
        "feature_dim = train_data.feature_dim\n",
        "\n",
        "#Setup of the model\n",
        "model = MICN(input_feature_dim = feature_dim, output_feature_dim = feature_dim, seq_len = seq_len, pred_len = pred_len, embedding_dim=embedding_dim, freq=freq, mode=mode,\n",
        "                dropout=dropout, conv_kern=conv_kern, decomp_kern=decomp_kern,  iso_kern=iso_kern).float().to(device=device)\n",
        "\n",
        "#Setup of the optimizer, the scheduler for adjusting the learning rate during the training, and the early stopping\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
        "criterion = nn.MSELoss()\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True)"
      ],
      "metadata": {
        "id": "rC2sSRO-5xYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we have the training code, followed by the validation process."
      ],
      "metadata": {
        "id": "GsbRXY_lCzKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"dataset: {filename_dataset}, feature_dim: {feature_dim}, pred_len: {pred_len}, iso_kern: {iso_kern}, mode: {mode}\")\n",
        "for epoch in range(epochs):\n",
        "\n",
        "            # Training Loop\n",
        "            train_losses = []\n",
        "            model.train()\n",
        "            for batch, (seq_x, seq_y, time_x, time_y) in enumerate(train_loader, 1):\n",
        "                # called at the beginning of the training step for each batch to ensure that the gradients computed for the current batch are not influenced by gradients from the previous batches.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                #forward pass compute predicted outputs\n",
        "                output = model(seq_x, time_y)\n",
        "                y_train = seq_y[:,-pred_len:,:].to(device)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss = criterion(output, y_train)\n",
        "                #backward pass: computes the gradients of the loss with respect to the model parameters\n",
        "                loss.backward()\n",
        "                #once the gradients are computed, model.step() update the parameters\n",
        "                optimizer.step()\n",
        "                if (batch+1) % 100 == 0:\n",
        "                    print(f\"iter: {batch+1} | epoch: {epoch+1} | loss: {loss.item():.5f}\")\n",
        "                train_losses.append(loss.item())\n",
        "\n",
        "            # Validation Loop\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_losses = []\n",
        "                for i, (seq_x, seq_y, time_x, time_y) in enumerate(val_loader):\n",
        "\n",
        "                    #forward pass compute predicted outputs\n",
        "                    output = model(seq_x, time_y)\n",
        "                    y_val = seq_y[:,-pred_len:,:].to(device)\n",
        "\n",
        "                    loss = criterion(output, y_val)\n",
        "                    val_losses.append(loss.item())\n",
        "\n",
        "            # calculate average loss over an epoch\n",
        "            train_loss = np.average(train_losses)\n",
        "            val_loss = np.average(val_losses)\n",
        "            print(f\"\\nEpoch: {epoch+1} | Train Loss: {train_loss:.5f} | Vali Loss: {val_loss:.5f}\")\n",
        "\n",
        "            early_stopping(val_loss, model, './checkpoints/')\n",
        "            if early_stopping.early_stop:\n",
        "                break\n",
        "\n",
        "            print(f\"Updating learning rate to {scheduler.get_last_lr()}\")\n",
        "            scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JRG9MAzCyZQ",
        "outputId": "316a087d-de58-4cb6-9701-6c65f2694f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: electricity.csv, feature_dim: 321, pred_len: 96, iso_kern: [17, 13], mode: regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv1d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 100 | epoch: 1 | loss: 0.22630\n",
            "iter: 200 | epoch: 1 | loss: 0.21461\n",
            "iter: 300 | epoch: 1 | loss: 0.19104\n",
            "iter: 400 | epoch: 1 | loss: 0.15732\n",
            "iter: 500 | epoch: 1 | loss: 0.16960\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.21424 | Vali Loss: 0.14211\n",
            "Validation loss decreased (inf --> 0.142110).  Saving model ...\n",
            "Updating learning rate to [0.001]\n",
            "iter: 100 | epoch: 2 | loss: 0.14477\n",
            "iter: 200 | epoch: 2 | loss: 0.15355\n",
            "iter: 300 | epoch: 2 | loss: 0.17048\n",
            "iter: 400 | epoch: 2 | loss: 0.13833\n",
            "iter: 500 | epoch: 2 | loss: 0.13493\n",
            "\n",
            "Epoch: 2 | Train Loss: 0.14223 | Vali Loss: 0.13075\n",
            "Validation loss decreased (0.142110 --> 0.130753).  Saving model ...\n",
            "Updating learning rate to [0.0005]\n",
            "iter: 100 | epoch: 3 | loss: 0.11894\n",
            "iter: 200 | epoch: 3 | loss: 0.13059\n",
            "iter: 300 | epoch: 3 | loss: 0.11882\n",
            "iter: 400 | epoch: 3 | loss: 0.12057\n",
            "iter: 500 | epoch: 3 | loss: 0.11668\n",
            "\n",
            "Epoch: 3 | Train Loss: 0.12526 | Vali Loss: 0.12810\n",
            "Validation loss decreased (0.130753 --> 0.128102).  Saving model ...\n",
            "Updating learning rate to [0.00025]\n",
            "iter: 100 | epoch: 4 | loss: 0.12523\n",
            "iter: 200 | epoch: 4 | loss: 0.11775\n",
            "iter: 300 | epoch: 4 | loss: 0.11433\n",
            "iter: 400 | epoch: 4 | loss: 0.11896\n",
            "iter: 500 | epoch: 4 | loss: 0.12513\n",
            "\n",
            "Epoch: 4 | Train Loss: 0.11752 | Vali Loss: 0.12736\n",
            "Validation loss decreased (0.128102 --> 0.127356).  Saving model ...\n",
            "Updating learning rate to [0.000125]\n",
            "iter: 100 | epoch: 5 | loss: 0.10951\n",
            "iter: 200 | epoch: 5 | loss: 0.11321\n",
            "iter: 300 | epoch: 5 | loss: 0.10860\n",
            "iter: 400 | epoch: 5 | loss: 0.10987\n",
            "iter: 500 | epoch: 5 | loss: 0.11532\n",
            "\n",
            "Epoch: 5 | Train Loss: 0.11372 | Vali Loss: 0.12811\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to [6.25e-05]\n",
            "iter: 100 | epoch: 6 | loss: 0.11126\n",
            "iter: 200 | epoch: 6 | loss: 0.11382\n",
            "iter: 300 | epoch: 6 | loss: 0.11505\n",
            "iter: 400 | epoch: 6 | loss: 0.10724\n",
            "iter: 500 | epoch: 6 | loss: 0.10834\n",
            "\n",
            "Epoch: 6 | Train Loss: 0.11164 | Vali Loss: 0.12816\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to [3.125e-05]\n",
            "iter: 100 | epoch: 7 | loss: 0.10404\n",
            "iter: 200 | epoch: 7 | loss: 0.10804\n",
            "iter: 300 | epoch: 7 | loss: 0.10711\n",
            "iter: 400 | epoch: 7 | loss: 0.11316\n",
            "iter: 500 | epoch: 7 | loss: 0.10794\n",
            "\n",
            "Epoch: 7 | Train Loss: 0.11052 | Vali Loss: 0.12704\n",
            "Validation loss decreased (0.127356 --> 0.127036).  Saving model ...\n",
            "Updating learning rate to [1.5625e-05]\n",
            "iter: 100 | epoch: 8 | loss: 0.10459\n",
            "iter: 200 | epoch: 8 | loss: 0.10332\n",
            "iter: 300 | epoch: 8 | loss: 0.10968\n",
            "iter: 400 | epoch: 8 | loss: 0.11503\n",
            "iter: 500 | epoch: 8 | loss: 0.10859\n",
            "\n",
            "Epoch: 8 | Train Loss: 0.10992 | Vali Loss: 0.12698\n",
            "Validation loss decreased (0.127036 --> 0.126979).  Saving model ...\n",
            "Updating learning rate to [7.8125e-06]\n",
            "iter: 100 | epoch: 9 | loss: 0.10472\n",
            "iter: 200 | epoch: 9 | loss: 0.10824\n",
            "iter: 300 | epoch: 9 | loss: 0.10824\n",
            "iter: 400 | epoch: 9 | loss: 0.11404\n",
            "iter: 500 | epoch: 9 | loss: 0.11122\n",
            "\n",
            "Epoch: 9 | Train Loss: 0.10962 | Vali Loss: 0.12732\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to [3.90625e-06]\n",
            "iter: 100 | epoch: 10 | loss: 0.11540\n",
            "iter: 200 | epoch: 10 | loss: 0.10605\n",
            "iter: 300 | epoch: 10 | loss: 0.11298\n",
            "iter: 400 | epoch: 10 | loss: 0.11098\n",
            "iter: 500 | epoch: 10 | loss: 0.10607\n",
            "\n",
            "Epoch: 10 | Train Loss: 0.10946 | Vali Loss: 0.12733\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to [1.953125e-06]\n",
            "iter: 100 | epoch: 11 | loss: 0.11225\n",
            "iter: 200 | epoch: 11 | loss: 0.10884\n",
            "iter: 300 | epoch: 11 | loss: 0.10781\n",
            "iter: 400 | epoch: 11 | loss: 0.11714\n",
            "iter: 500 | epoch: 11 | loss: 0.10920\n",
            "\n",
            "Epoch: 11 | Train Loss: 0.10937 | Vali Loss: 0.12720\n",
            "EarlyStopping counter: 3 out of 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we have the evaluation process that will compute the performance of the model (MSE and MAE)."
      ],
      "metadata": {
        "id": "2g_vwcbYDjVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "print('Evaluation:')\n",
        "model.load_state_dict(torch.load('./checkpoints/checkpoint.pth'))\n",
        "model.eval()\n",
        "\n",
        "predictions, truths = [], []\n",
        "with torch.no_grad():\n",
        "    for _, (seq_x, seq_y, time_x, time_y) in enumerate(test_loader):\n",
        "\n",
        "        #forward pass compute predicted outputs\n",
        "        prediction = model(seq_x, time_y)\n",
        "        truth = seq_y[:,-pred_len:,:].to(device)\n",
        "\n",
        "        predictions.append(prediction)\n",
        "        truths.append(truth)\n",
        "\n",
        "#Convert lists into pytorch tensors\n",
        "predictions_tensor, truths_tensor = torch.stack(predictions), torch.stack(truths)\n",
        "\n",
        "# Compute Mean Squared Error (MSE) and Mean Absolute Error (MAE)\n",
        "mse = torch.mean((predictions_tensor - truths_tensor) ** 2).item()\n",
        "mae = torch.mean(torch.abs(predictions_tensor - truths_tensor)).item()\n",
        "print(f'MSE: {mse:.5f} | MAE: {mae:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3vBgm-ED5tA",
        "outputId": "b6e43234-5643-4834-d9a0-6b853e1f283a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation:\n",
            "MSE: 0.16290 | MAE: 0.27200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Results**\n",
        "\n",
        "In the following, we will show the results obtained from the paper author's model and compare them with the results obtained from our reimplemented model. Specifically, for each of the datasets we performed 3 tests, since there is randomness during the training process (e.g. due to the shuffling applied by the dataloader or from the initialization to random values of some weights). The numbers we have included in the table below, derived from the average of the values obtained from the 3 tests.\n",
        "\n",
        "Some tests were performed locally through a NVIDIA RTX 3050 Ti 4GB GPU. Other tests, due to the limited memory of the video card, were performed on Google Colab with an NVIDIA T4 GPU provided by Colab.\n",
        "\n",
        "Some types of tests, i.e., those involving datasets with very large and with more than 800 features or with a prediction length of 720, we were unable to perform the training because of lack of computational power of the GPU, or because of the time it would have been necessary to keep the Colab session active.We marked them in the table with '---' signature.\n",
        "\n",
        "As we can see from the table below, we were able to obtain results very close to those presented in the paper. The table on the left represents the results of the original paper, while the table on the right represents the results of our model."
      ],
      "metadata": {
        "id": "lJ3wt5E_tKfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Results](https://github.com/Awenega/MICN/blob/main/images/results.png?raw=true)"
      ],
      "metadata": {
        "id": "XkXoMonKwglk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following table, instead, represents the comparison of the model proposed by the original paper with all other models that address the same problem, that is, long-term series forecasting.\n",
        "\n",
        "Bold results are the best ones. As we can see, MICN completely outperforms all other models."
      ],
      "metadata": {
        "id": "Y0bTZETpFOoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Results comparison](https://github.com/Awenega/MICN/blob/main/images/original%20results.png?raw=true)"
      ],
      "metadata": {
        "id": "vgyAT196Eji-"
      }
    }
  ]
}
